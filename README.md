# Extended Kalman Filter Project
Self-Driving Car Engineer Nanodegree Program for learning Sensor Fusion based on Extended kalman filter.

In this project I implemented a kalman filter to estimate the state of a moving object of interest with noisy lidar and radar measurements. Passing the project requires obtaining RMSE values that are lower than the tolerance outlined in the project rubric. 

This project involves the Term 2 Simulator which can be downloaded [here](https://github.com/udacity/self-driving-car-sim/releases)
This simulator is necessary for check accuracy of the Sensor Fusion

This repository includes two files that can be used to set up and install [uWebSocketIO](https://github.com/uWebSockets/uWebSockets) for either Linux or Mac systems. For windows you can use either Docker, VMware, or even [Windows 10 Bash on Ubuntu](https://www.howtogeek.com/249966/how-to-install-and-use-the-linux-bash-shell-on-windows-10/) to install uWebSocketIO. Please see [this concept in the classroom](https://classroom.udacity.com/nanodegrees/nd013/parts/40f38239-66b6-46ec-ae68-03afd8a601c8/modules/0949fca6-b379-42af-a919-ee50aa304e6a/lessons/f758c44c-5e40-4e01-93b5-1a82aa4e044f/concepts/16cf4a78-4fc7-49e1-8621-3450ca938b77) for the required version and installation scripts.

Once the install for uWebSocketIO is complete, the main program can be built and run by doing the following from the project top directory.

1. mkdir build
2. cd build
3. cmake ..
4. make
5. ./ExtendedKF

Tips for setting up your environment can be found [here](https://classroom.udacity.com/nanodegrees/nd013/parts/40f38239-66b6-46ec-ae68-03afd8a601c8/modules/0949fca6-b379-42af-a919-ee50aa304e6a/lessons/f758c44c-5e40-4e01-93b5-1a82aa4e044f/concepts/23d376c7-0195-4276-bdf0-e02f1f3c665d)

I modified the following files: src/FusionEKF.cpp, src/FusionEKF.h, kalman_filter.cpp, kalman_filter.h, tools.cpp, and tools.h

Here is the main protcol that main.cpp uses for uWebSocketIO in communicating with the simulator. I used provided main.cpp for checking my achievement.


INPUT: values provided by the simulator to the c++ program

["sensor_measurement"] => the measurement that the simulator observed (either lidar or radar)


OUTPUT: values provided by the c++ program to the simulator

["estimate_x"] <= kalman filter estimated position x
["estimate_y"] <= kalman filter estimated position y
["rmse_x"]
["rmse_y"]
["rmse_vx"]
["rmse_vy"]

---

## Other Important Dependencies

* cmake >= 3.5
  * All OSes: [click here for installation instructions](https://cmake.org/install/)
* make >= 4.1 (Linux, Mac), 3.81 (Windows)
  * Linux: make is installed by default on most Linux distros
  * Mac: [install Xcode command line tools to get make](https://developer.apple.com/xcode/features/)
  * Windows: [Click here for installation instructions](http://gnuwin32.sourceforge.net/packages/make.htm)
* gcc/g++ >= 5.4
  * Linux: gcc / g++ is installed by default on most Linux distros
  * Mac: same deal as make - [install Xcode command line tools](https://developer.apple.com/xcode/features/)
  * Windows: recommend using [MinGW](http://www.mingw.org/)

## Basic Build Instructions

1. Clone this repo.
2. Make a build directory: `mkdir build && cd build`
3. Compile: `cmake .. && make` 
   * On windows, you may need to run: `cmake .. -G "Unix Makefiles" && make`
4. Run it: `./ExtendedKF `

## Editor Settings

We've purposefully kept editor configuration files out of this repo in order to
keep it as simple and environment agnostic as possible. However, we recommend
using the following settings:

* indent using spaces
* set tab width to 2 spaces (keeps the matrices in source code aligned)

## Code Style

I mainly refer to [Google's C++ style guide](https://google.github.io/styleguide/cppguide.html).
I applied cpplint to each of files which I updated.
I removed warning and error message generated by cpplint as possible.


## Project Instructions and Rubric

Note: regardless of the changes you make, your project must be buildable using
cmake and make!

More information is only accessible by people who are already enrolled in Term 2
of CarND. If you are enrolled, see [the project resources page](https://classroom.udacity.com/nanodegrees/nd013/parts/40f38239-66b6-46ec-ae68-03afd8a601c8/modules/0949fca6-b379-42af-a919-ee50aa304e6a/lessons/f758c44c-5e40-4e01-93b5-1a82aa4e044f/concepts/382ebfd6-1d55-4487-84a5-b6a5a4ba1e47)
for instructions and the project rubric.


# Explanation of my work

## Design and Implementation of the Fusion
 I implemented Sensor Fusion based on Kalman filter. This sensor fusion estimates position and velocity of a moving object with getting sensing information both of radar and lidar.

 Sensing data from radar are different from those of lidar. Object position gained by lidar is linear, but that obtained by radar is not linear. Normal Kalman filter can't deal with non-linear object position. 
 
 I used Extended kalman filter(EKF) for realizing sensor fusion which can use radar and lidar. Kalman filter generally have two steps: prediction and measurement. These two steps are executed repeatedly.
 
 In this source code, `Predict()` method in kalman_filter.cpp is used on prediction phase. `UpdateEKF()` method is corresponded to radar measurement and `Update()` method is dedicated to lidar measurement. Sensor fusion uses these three methods in `ProcessMeasurement()` method in FusionEKF.cpp.
 
 Before starting iteration loop of prediction and measurement, Fusion initilize state vectors and required matrixes. These processing are realized in `InitialTracking` of FusionEKF.cpp.
 
 Considering consistency of source code description, I defined setter/getter methods in kalman_filter.cpp. Some common functions are implemented in helper class called `Tools`.
 
 Those are overview of my implementation. If reviewer see details of my source code, please check [src directory](./src/)
 
 
## Achievement
 According to [project rubic](https://review.udacity.com/#!/rubrics/748/view), sensor fusion should estimates position and velocity as px, py, vx, and vy RMSE should be less than equal to the values [.11, .11, 0.52, 0.52] against running Dataset1.
 
 My sensor fusion gained RMSE as [0.0964, 0.853, 0.4154, 0.4316] at the end of execution. I think that my sensor fusion fulfill minimum requirement for submission.
 
 From viewpoint of accuracy, my submission must fulfill requirement shown in project rubic.
